{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Nasdaq News Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nasdaq (National Association of Securities Dealers Automated Quotations) Stock Market is an electronic stock exchange in the United States. It is the second largest stock exchange in the world by market capitalization.\n",
    "\n",
    "The Nasdaq Stock Market website provides stock market news, business news, and financial news useful for data analysis on stocks and trading.\n",
    "\n",
    "Web scraping or extract information from Nasdaq news website allows us to perform stock price prediction, stock market sentiment analysis, and equity research, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrap most active Nasdaq stocks from Nasdaq news website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.nasdaq.com/news/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import urllib.request\n",
    "\n",
    "#import the Beautiful soup function to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the url\n",
    "nasdaq = \"https://www.nasdaq.com/markets/most-active.aspx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the connection and download html page from url\n",
    "webpage = urllib.request.urlopen(nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the html data in the 'webpage' variable and save as Beautiful Soup format\n",
    "soup = BeautifulSoup(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nested structure of the html page\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=soup.find_all('div', attrs='genTable')\n",
    "all_rows=table[1].find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate lists\n",
    "symbol=[]\n",
    "\n",
    "name=[]\n",
    "\n",
    "last_sale=[]\n",
    "\n",
    "change_net=[]\n",
    "\n",
    "share_volume=[]\n",
    "\n",
    " \n",
    "for row in all_rows:\n",
    "\n",
    "    cols=row.find_all('td')\n",
    "\n",
    "    if(len(cols)):\n",
    "        symbol.append(cols[0].text)\n",
    "        \n",
    "        name.append(cols[1].text)\n",
    "\n",
    "        last_sale.append(cols[3].text)\n",
    "\n",
    "        change_net.append(cols[4].text)\n",
    "\n",
    "        share_volume.append(cols[5].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = [x.replace('\\n', '') for x in symbol]\n",
    "symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# dictionary of lists  \n",
    "dict = {'Symbol': symbol, 'Name': name, 'Last_sale': last_sale, 'Change_net': change_net, \n",
    "        'Share_volume': share_volume}  \n",
    "\n",
    "# Save as dataframe\n",
    "df = pd.DataFrame(dict) \n",
    "    \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
